# ğŸ“Š Customer Churn Prediction App

A web-based machine learning application that predicts **customer churn** â€” i.e., whether a customer is likely to leave a service â€” using a **Logistic Regression** model built within a **scikit-learn pipeline**. The app is deployed with a clean and interactive **Streamlit** interface.

---

## ğŸ§  Overview

The app takes customer details such as **tenure, contract type, and monthly charges** as input and provides a **real-time prediction** (Stay or Churn) along with a **probability score**.  
It is designed for telecom or subscription-based businesses seeking quick churn risk insights.

---

## ğŸ“¸ Application Demo

> *(Recommended: Add a screenshot or GIF of your running application here!)*

Example:

```
[Insert image: app_screenshot.png]
```

---

## âœ¨ Features

- **ğŸ› Interactive Sidebar:** Input all 19 required customer features easily.
- **âš¡ Real-Time Prediction:** Instantly predicts churn using the trained model pipeline.
- **ğŸ“ˆ Probability Score:** Displays model confidence via a dynamic progress bar.
- **ğŸ¨ Dynamic UI Feedback:** Color-coded message for CHURN (ğŸ”´) or STAY (ğŸŸ¢).
- **ğŸ”— End-to-End Pipeline:** Preprocessing (imputation, scaling, encoding) handled inside the pipeline â€” no manual steps needed.

---

## ğŸ› ï¸ Technology Stack

| Component | Description |
|------------|-------------|
| **Python 3.x** | Core programming language |
| **Streamlit** | For the interactive front-end and deployment |
| **Scikit-learn** | For building the ML pipeline and logistic regression model |
| **Pandas** | Data manipulation and input handling |
| **Joblib** | Model serialization (saving/loading trained pipeline) |

---

## âš™ï¸ Installation & Setup

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

### 2. Create and Activate a Virtual Environment (Recommended)
```bash
python -m venv venv
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 3. Install Dependencies
Create a `requirements.txt` file (if not already present) with the following:

```
streamlit
pandas
scikit-learn
```

Then install:
```bash
pip install -r requirements.txt
```

### 4. Ensure the Model Artifact Exists
The app requires the trained model file:  
`artifacts/model.pkl`

If missing, run the model training notebook to generate it:
```
notebooks/02-model-building.ipynb
```

### 5. Run the Application
```bash
streamlit run app.py
```

Your default browser should open automatically with the running app.

---

## ğŸ“ Project Structure

```
customer-churn-prediction/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                <-- You are here!
â”œâ”€â”€ requirements.txt         <-- All project dependencies
â”œâ”€â”€ app.py                   <-- Streamlit application file
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01-data-exploration.ipynb
â”‚   â””â”€â”€ 02-model-building.ipynb  <-- Model training & pipeline creation
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ churn_data.csv       <-- Raw dataset used for training
â”‚
â””â”€â”€ artifacts/
    â””â”€â”€ model.pkl                <-- Trained scikit-learn pipeline
```

---

## ğŸ§© Model & Preprocessing Details

The `model.pkl` file is a **scikit-learn Pipeline** object that encapsulates all data transformations and the classifier.  
This ensures that the exact same preprocessing steps are applied to both training and live inputs.

### Pipeline Components

#### **1. Numerical Columns (`num_cols`)**
- **KNNImputer:** Fills missing values using 5 nearest neighbors  
- **StandardScaler:** Normalizes data (mean = 0, std = 1)

#### **2. Categorical Columns (`cat_cols`)**
- **SimpleImputer:** Replaces missing values with most frequent category  
- **OneHotEncoder:** Encodes categorical features (drops first category to avoid multicollinearity)

#### **3. Ordered Columns (`ordered_cols`)**
- **SimpleImputer:** Replaces missing values with most frequent category  
- **OneHotEncoder:** Encodes ordered categorical variables (e.g., contract duration)

#### **4. Classifier**
- **Model:** `LogisticRegression`  
- **Parameters:** `C=1`, `solver='liblinear'`

---

## ğŸš€ How to Use

1. **Enter Customer Information:**  
   Use the Streamlit sidebar to input all customer details.

2. **Get Prediction:**  
   Click **"Predict Churn"**.

3. **View Results:**  
   - Probability bar shows likelihood of churn  
   - Color-coded result:
     - ğŸŸ¢ **STAY** â€” customer is likely to stay
     - ğŸ”´ **CHURN** â€” customer is likely to leave

---

## ğŸ§° Troubleshooting

| Issue | Possible Fix |
|-------|---------------|
| `model.pkl not found` | Run the model training notebook or ensure itâ€™s placed in `artifacts/`. |
| Missing library errors | Run `pip install -r requirements.txt` again. |
| Streamlit app not launching | Ensure the virtual environment is activated and port 8501 is free. |

---

## ğŸ‘¥ Contributors

- **Your Name** â€“ *Developer & Maintainer*  
- *(Add additional contributors if applicable)*

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.
